{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Subset, random_split\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "from train_utils import *\n",
    "from train_xor import *\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate training seeds\n",
    "#seeds = torch.randint(0, 2**12, (6,)).tolist()\n",
    "#seeds\n",
    "seeds = [3313, 1998, 1900, 1608, 3585, 96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions for preparing domino dataset\n",
    "\n",
    "def prepare_domino_data(\n",
    "    root,\n",
    "    train_transform,\n",
    "    test_transform,\n",
    "    val_frac=0.25,\n",
    "):\n",
    "    train_data = torchvision.datasets.ImageFolder(\n",
    "        root=root, transform=train_transform\n",
    "    )\n",
    "    val_data = torchvision.datasets.ImageFolder(\n",
    "        root=root, transform=test_transform\n",
    "    )\n",
    "\n",
    "    train_ind, val_ind = random_split(\n",
    "        range(len(train_data)), [1 - val_frac, val_frac]\n",
    "    )\n",
    "    train_data = Subset(train_data, train_ind)\n",
    "    val_data = Subset(val_data, val_ind)\n",
    "    return train_data, val_data\n",
    "\n",
    "def prepare_resnet18(num_classes, scale=1.0):\n",
    "    model = resnet18(num_classes=num_classes)\n",
    "    model.conv1 = nn.Conv2d(\n",
    "        3, 64, kernel_size=3, stride=1, padding=1, bias=False\n",
    "    ) #small convolution is better for CIFAR-10\n",
    "    with torch.no_grad():\n",
    "        for parameter in model.parameters():\n",
    "            parameter.copy_(parameter * scale)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize layer for concatenated images\n",
    "\n",
    "class Normalize(torch.nn.Module):\n",
    "    def __init__(self, means, stds):\n",
    "        super().__init__()\n",
    "        self.trans1 = transforms.Normalize(means[0], stds[0])\n",
    "        self.trans2 = transforms.Normalize(means[1], stds[1])\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        dtype = tensor.dtype\n",
    "        tensor1 = self.trans1(tensor[:, :32, :])\n",
    "        tensor2 = self.trans2(tensor[:, 32:, :])\n",
    "        return torch.cat((tensor1, tensor2), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for logisic regression during training\n",
    "\n",
    "def ood_correct_training_params(\n",
    "    epochs,\n",
    "    train_loader,\n",
    "    loader_params,\n",
    "    optimizer_params,\n",
    "    scheduler_params,\n",
    "    train_params,\n",
    "    stats,\n",
    "    ood_data_params,\n",
    "    ood_reg_params={},\n",
    "    ood_data_seed=None,\n",
    "    ood_seed=None,\n",
    "    ood_data_fn=prepare_data,\n",
    "    ood_reg_fn=lambda **x: LogisticRegression(**x),\n",
    "    id_correct_training_params_fn=correct_training_params,\n",
    "    **id_correct_training_params\n",
    "):\n",
    "    id_correct_training_params_fn(\n",
    "        epochs,\n",
    "        train_loader,\n",
    "        loader_params,\n",
    "        optimizer_params,\n",
    "        scheduler_params,\n",
    "        train_params,\n",
    "        **id_correct_training_params\n",
    "    )\n",
    "\n",
    "    set_deterministic_seed(ood_data_seed)\n",
    "    ood_val_data, ood_test_data = ood_data_fn(**ood_data_params)\n",
    "    train_params['val_epoch_params']['ood_val_data'] = ood_val_data\n",
    "    train_params['val_epoch_params']['ood_test_data'] = ood_test_data\n",
    "    train_params['val_epoch_params']['stats'] = stats\n",
    "    train_params['val_epoch_params']['ood_reg_fn'] \\\n",
    "        = ood_reg_fn(**ood_reg_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = [[0.1307, 0.1307, 0.1307], [0.491, 0.482, 0.446]]\n",
    "stds = [[0.3081, 0.3081, 0.3081], [0.202, 0.199, 0.201]]\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    Normalize(means, stds),\n",
    "])\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    test_transform\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare training parameters\n",
    "\n",
    "root = '/mnt/files/data'\n",
    "epochs = 1\n",
    "\n",
    "seed = 179\n",
    "stats = [[], [], [], []]\n",
    "\n",
    "data_params = {\n",
    "    'root': root + '/mnist-cifar10-train-100',\n",
    "    'train_transform': train_transform,\n",
    "    'test_transform': test_transform,\n",
    "}\n",
    "loader_params = {'batch_size': 2**7, 'num_workers': 4}\n",
    "model_params = {\n",
    "    'num_classes': 10,\n",
    "    'scale': 2**(-5)\n",
    "}\n",
    "loss_params = {}\n",
    "optimizer_params = {\n",
    "    'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True\n",
    "}\n",
    "scheduler_params = {}\n",
    "correction_params = {\n",
    "    'lr_factor': 2**(-10),\n",
    "    'warmup_factor': 2**(-3),\n",
    "    'stats': stats,\n",
    "    'ood_data_params': {\n",
    "        'root': root + '/mnist-cifar10-test',\n",
    "        'train_transform': test_transform,\n",
    "        'test_transform': test_transform},\n",
    "    'ood_reg_params': {\n",
    "        'C': 1e3,\n",
    "        'max_iter': 20000,\n",
    "        'n_jobs': 1,\n",
    "        'warm_start': True},\n",
    "    'ood_data_seed': seed,\n",
    "    'ood_data_fn': prepare_domino_data,\n",
    "    'ood_reg_fn': lambda **x: LogisticRegression(**x)\n",
    "}\n",
    "\n",
    "train_params = {\n",
    "    'val_epoch_fn': ood_epoch,\n",
    "    'val_epoch_params': {\n",
    "        'feature_index': 'avgpool',\n",
    "        'loader_params': loader_params,\n",
    "        'warm_start_restarts': 50},\n",
    "    'val_interval': max(epochs//4, 1)\n",
    "}\n",
    "\n",
    "train_kwargs = {\n",
    "    'data_fn': prepare_domino_data,\n",
    "    'model_fn': prepare_resnet18,\n",
    "    'correct_training_params_fn': ood_correct_training_params\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_experiment(data_params, model_params):\n",
    "    experiment = []\n",
    "    for i in tqdm(range(len(seeds))):\n",
    "        seed = seeds[i]\n",
    "        stats = [[], [], [], []]\n",
    "\n",
    "        correction_params['stats'] = stats\n",
    "        correction_params['ood_data_seed'] = seed\n",
    "        _ = get_trained_model(\n",
    "            epochs,\n",
    "            data_params, loader_params,\n",
    "            model_params, loss_params,\n",
    "            optimizer_params, scheduler_params, correction_params,\n",
    "            train_params,\n",
    "            seed, seed, seed, seed,\n",
    "            **train_kwargs\n",
    "        )\n",
    "\n",
    "        experiment.append(stats)\n",
    "    return experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train models in different settings\n",
    "\n",
    "epochs = 2**8\n",
    "#epochs = 1\n",
    "#seeds = [179]\n",
    "\n",
    "train_params['range_fn'] = lambda x: range(x)\n",
    "train_params['val_epoch_params']['print_fn'] = lambda *x: None\n",
    "train_params['val_epoch_params']['print_ood'] = lambda *x: None\n",
    "train_params['val_interval'] = epochs // 16\n",
    "\n",
    "experiments = []\n",
    "for scale, train_dir in zip(\n",
    "    (2**(-5), 1, 2**(-5)),\n",
    "    ('/mnist-cifar10-train-100',\n",
    "     '/mnist-cifar10-train-100',\n",
    "     '/mnist-cifar10-train-95')\n",
    "):\n",
    "    data_params['root'] = root + train_dir\n",
    "    model_params['scale'] = scale\n",
    "    experiments.append(make_experiment(data_params, model_params))\n",
    "\n",
    "experiments = np.array(experiments)\n",
    "with open('domino.npy', 'wb') as f:\n",
    "    np.save(f, experiments)\n",
    "\n",
    "del correction_params['ood_reg_params']['C']\n",
    "correction_params['ood_reg_params']['penalty'] = None\n",
    "data_params['root'] = root + '/mnist-cifar10-train-100'\n",
    "model_params['scale'] = 2**(-5)\n",
    "train_params['val_interval'] = epochs // 4\n",
    "\n",
    "experiment_no_reg = make_experiment(data_params, model_params)\n",
    "\n",
    "experiment_no_reg = np.array(experiment_no_reg)\n",
    "with open('domino_no_reg.npy', 'wb') as f:\n",
    "    np.save(f, experiment_no_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t, norm\n",
    "\n",
    "x = experiments[0, :, 1]\n",
    "diff = x[:, 4] - x[:, 16]\n",
    "mean, std = diff.mean(), diff.std(ddof=1)\n",
    "t_val = mean * len(diff)**0.5 / std\n",
    "p_val = t.sf(t_val, len(diff)-1)\n",
    "print(f\"{mean:2.2%}, {std:2.2%}, {p_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = experiments[1, :, 1]\n",
    "diff = x[:, 4] - x[:, 16]\n",
    "mean, std = diff.mean(), diff.std(ddof=1)\n",
    "t_val = mean * len(diff)**0.5 / std\n",
    "p_val = t.sf(t_val, len(diff)-1)\n",
    "print(f\"{mean:2.2%}, {std:2.2%}, {p_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.sf(mean / std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
